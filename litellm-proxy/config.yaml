model_list:
  # OpenAI models
  - model_name: openai/o4-mini
    litellm_params:
      model: openai/o4-mini
      api_key: "os.environ/OPENAI_API_KEY"
  - model_name: openai/o3-mini
    litellm_params:
      model: openai/o3-mini
      api_key: "os.environ/OPENAI_API_KEY"
  - model_name: openai/gpt-4.1-mini
    litellm_params:
      model: openai/gpt-4.1-mini
      api_key: "os.environ/OPENAI_API_KEY"
  - model_name: openai/gpt-4.1-nano
    litellm_params:
      model: openai/gpt-4.1-nano
      api_key: "os.environ/OPENAI_API_KEY"
  - model_name: openai/gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: "os.environ/OPENAI_API_KEY"    
  - model_name: openai/gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: "os.environ/OPENAI_API_KEY"

  # Anthropic models
  - model_name: antropic/claude-sonnet-4-20250514
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: "os.environ/ANTHROPIC_API_KEY"
  - model_name: antropic/claude-3-5-sonnet-20240620
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20240620
      api_key: "os.environ/ANTHROPIC_API_KEY"
  - model_name: antropic/claude-3-haiku-2024030
    litellm_params:
      model: anthropic/claude-3-haiku-2024030
      api_key: "os.environ/ANTHROPIC_API_KEY"
    provider: anthropic
      
  # Google Gemini models
  - model_name: google/gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: "os.environ/GOOGLE_GEMINI_API_KEY"

  # Perplexity models
  - model_name: perplexity/sonar-pro
    litellm_params:
      model: perplexity/sonar-pro
      api_key: "os.environ/PERPLEXITYAI_API_KEY"

  # other models
  - model_name: huggingface/deepseek-r1
    litellm_params:
      model: huggingface/together/deepseek-ai/DeepSeek-R1
      api_key: os.environ/HF_TOKEN


# Cost tracking
cost_tracking:
  enabled: true
  cost_file: ./costs.json
  detailed_view: true

# Usage limits and logging settings
litellm_settings:
  database_url: "${LITELLM_DB_URL}"
  set_verbose: false
  store_model_in_db: true

# Logging
general_settings:
  proxy_logging: false
  verbose: false
  log_level: "ERROR"
